{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import input_data\n",
    "import scipy.ndimage.interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "mb_size = 32\n",
    "z_dim = 10\n",
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-3\n",
    "\n",
    "def log(x):\n",
    "    return torch.log(x + 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_AB = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_dim, X_dim),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "G_BA = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_dim, X_dim),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "D_A = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_dim, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "D_B = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_dim, h_dim),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_dim, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "nets = [G_AB, G_BA, D_A, D_B]\n",
    "G_params = list(G_AB.parameters()) + list(G_BA.parameters())\n",
    "D_params = list(D_A.parameters()) + list(D_B.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    for net in nets:\n",
    "        net.zero_grad()\n",
    "\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=lr)\n",
    "D_solver = optim.Adam(D_params, lr=lr)\n",
    "\n",
    "if not os.path.exists('out_discoGAN/'):\n",
    "    os.makedirs('out_discoGAN/')\n",
    "\n",
    "# Gather training data: domain1 <- real MNIST img, domain2 <- rotated MNIST img\n",
    "X_train = mnist.train.images\n",
    "half = int(X_train.shape[0] / 2)\n",
    "# Real image\n",
    "X_train1 = X_train[:half]\n",
    "# Rotated image\n",
    "X_train2 = X_train[half:].reshape(-1, 28, 28)\n",
    "X_train2 = scipy.ndimage.interpolation.rotate(X_train2, 90, axes=(1, 2))\n",
    "X_train2 = X_train2.reshape(-1, 28*28)\n",
    "# Cleanup\n",
    "del X_train\n",
    "\n",
    "def sample_x(X, size):\n",
    "    start_idx = np.random.randint(0, X.shape[0]-size)\n",
    "    return Variable(torch.from_numpy(X[start_idx:start_idx+size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; D_loss: 0.6043; G_loss: 29.03\n",
      "Iter-10000; D_loss: 1.187; G_loss: 26.79\n",
      "Iter-20000; D_loss: 0.4727; G_loss: 26.82\n",
      "Iter-30000; D_loss: 0.653; G_loss: 26.24\n",
      "Iter-40000; D_loss: 0.8126; G_loss: 27.74\n",
      "Iter-50000; D_loss: 0.4059; G_loss: 24.84\n",
      "Iter-60000; D_loss: 0.781; G_loss: 27.1\n",
      "Iter-70000; D_loss: 0.6632; G_loss: 25.77\n",
      "Iter-80000; D_loss: 0.9447; G_loss: 27.14\n",
      "Iter-90000; D_loss: 0.9967; G_loss: 29.95\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for it in range(100000):\n",
    "    # Sample data from both domains\n",
    "    X_A = sample_x(X_train1, mb_size)\n",
    "    X_B = sample_x(X_train2, mb_size)\n",
    "\n",
    "    # Discriminator A\n",
    "    X_BA = G_BA(X_B)\n",
    "    D_A_real = D_A(X_A)\n",
    "    D_A_fake = D_A(X_BA)\n",
    "\n",
    "    L_D_A = -torch.mean(log(D_A_real) + log(1 - D_A_fake))\n",
    "\n",
    "    # Discriminator B\n",
    "    X_AB = G_AB(X_A)\n",
    "    D_B_real = D_B(X_B)\n",
    "    D_B_fake = D_B(X_AB)\n",
    "\n",
    "    L_D_B = -torch.mean(log(D_B_real) + log(1 - D_B_fake))\n",
    "\n",
    "    # Total discriminator loss\n",
    "    D_loss = L_D_A + L_D_B\n",
    "\n",
    "    D_loss.backward()\n",
    "    D_solver.step()\n",
    "    reset_grad()\n",
    "\n",
    "    # Generator AB\n",
    "    X_AB = G_AB(X_A)\n",
    "    D_B_fake = D_B(X_AB)\n",
    "    X_ABA = G_BA(X_AB)\n",
    "\n",
    "    L_adv_B = -torch.mean(log(D_B_fake))\n",
    "    L_recon_A = torch.mean(torch.sum((X_A - X_ABA)**2, 1))\n",
    "    L_G_AB = L_adv_B + L_recon_A\n",
    "\n",
    "    # Generator BA\n",
    "    X_BA = G_BA(X_B)\n",
    "    D_A_fake = D_A(X_BA)\n",
    "    X_BAB = G_AB(X_BA)\n",
    "\n",
    "    L_adv_A = -torch.mean(log(D_A_fake))\n",
    "    L_recon_B = torch.mean(torch.sum((X_B - X_BAB)**2, 1))\n",
    "    L_G_BA = L_adv_A + L_recon_B\n",
    "\n",
    "    # Total generator loss\n",
    "    G_loss = L_G_AB + L_G_BA\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 10000 == 0:\n",
    "        print('Iter-{}; D_loss: {:.4}; G_loss: {:.4}'.format(it, D_loss, G_loss))\n",
    "#         print(it, ' G_loss:', G_loss, ' D_loss:', D_loss)\n",
    "        input_A = sample_x(X_train1, size=4)\n",
    "        input_B = sample_x(X_train2, size=4)\n",
    "\n",
    "        samples_A = G_BA(input_B).data.numpy()\n",
    "        samples_B = G_AB(input_A).data.numpy()\n",
    "\n",
    "        input_A = input_A.data.numpy()\n",
    "        input_B = input_B.data.numpy()\n",
    "\n",
    "        # The resulting image sample would be in 4 rows:\n",
    "        # row 1: real data from domain A, row 2 is its domain B translation\n",
    "        # row 3: real data from domain B, row 4 is its domain A translation\n",
    "        samples = np.vstack([input_A, samples_B, input_B, samples_A])\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out_discoGAN/{}.png'\n",
    "                    .format(str(cnt).zfill(3)), bbox_inches='tight')\n",
    "        cnt += 1\n",
    "        plt.close(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
